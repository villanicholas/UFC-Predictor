{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Data file - Dropping Features and Converting Categorical to Numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/out.csv\")\n",
    "\n",
    "# Modify the 'winner' column based on conditions\n",
    "data['winner'] = data.apply(lambda row: 1 if row['winner'] == row['fighter_1'] else 0, axis=1)\n",
    "\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['fight_id', 'fighter_1_id', 'fighter_1', 'fighter_2', 'fighter_2_id','decision_method','fight_duration_lastrnd','time_format','date', 'location','height_x','name_x','weight_x','height_y','name_y','weight_y' ]\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the first few rows of the cleaned data\n",
    "data_cleaned.head()\n",
    "\n",
    "data_cleaned.to_csv(\"data/cleanedData2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_882688/1623933302.py:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  '''keep = np.array([4,2,1,6,10,11,12,37,38,63,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,104,105,130,132,133,134,135,136,137,138,139,140,141,142,143,144,145]) - 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>decision_method</th>\n",
       "      <th>fight_duration_lastrnd</th>\n",
       "      <th>fight_duration_lastrnd_time</th>\n",
       "      <th>time_format</th>\n",
       "      <th>weight_class</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>dob_x</th>\n",
       "      <th>height_x</th>\n",
       "      <th>...</th>\n",
       "      <th>win_percentage_x</th>\n",
       "      <th>win_percentage_y</th>\n",
       "      <th>reach_advantage</th>\n",
       "      <th>total_fights_x</th>\n",
       "      <th>total_fights_y</th>\n",
       "      <th>finishing_rate_x</th>\n",
       "      <th>finishing_rate_y</th>\n",
       "      <th>age_x</th>\n",
       "      <th>age_y</th>\n",
       "      <th>age_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>November 02, 2019</td>\n",
       "      <td>92</td>\n",
       "      <td>835</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.242500</td>\n",
       "      <td>0.406154</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>September 28, 2019</td>\n",
       "      <td>37</td>\n",
       "      <td>256</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.398333</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>November 16, 2019</td>\n",
       "      <td>126</td>\n",
       "      <td>612</td>\n",
       "      <td>5' 5\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.603750</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>October 05, 2019</td>\n",
       "      <td>78</td>\n",
       "      <td>286</td>\n",
       "      <td>5' 5\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.196250</td>\n",
       "      <td>0.096250</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>October 18, 2019</td>\n",
       "      <td>23</td>\n",
       "      <td>466</td>\n",
       "      <td>6' 7\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>80</td>\n",
       "      <td>126</td>\n",
       "      <td>5' 6\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.186087</td>\n",
       "      <td>0.092069</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>80</td>\n",
       "      <td>737</td>\n",
       "      <td>5' 2\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.430714</td>\n",
       "      <td>0.351765</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>80</td>\n",
       "      <td>606</td>\n",
       "      <td>5' 9\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.393750</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>80</td>\n",
       "      <td>901</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.510667</td>\n",
       "      <td>0.187037</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>80</td>\n",
       "      <td>182</td>\n",
       "      <td>5' 7\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.156190</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3827 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      winner  decision_method  fight_duration_lastrnd  \\\n",
       "0          0                3                       3   \n",
       "1          1                7                       3   \n",
       "2          0                4                       3   \n",
       "3          1                7                       3   \n",
       "4          0                4                       3   \n",
       "...      ...              ...                     ...   \n",
       "3822       1                4                       3   \n",
       "3823       0                8                       3   \n",
       "3824       1                4                       3   \n",
       "3825       0                5                       2   \n",
       "3826       0                3                       3   \n",
       "\n",
       "      fight_duration_lastrnd_time  time_format  weight_class  \\\n",
       "0                             292            1             2   \n",
       "1                             164            1             0   \n",
       "2                             292            1            58   \n",
       "3                             173            1             0   \n",
       "4                             292            1             4   \n",
       "...                           ...          ...           ...   \n",
       "3822                          292            1             3   \n",
       "3823                          109            1            61   \n",
       "3824                          292            1            58   \n",
       "3825                           84            1             2   \n",
       "3826                          292            1             3   \n",
       "\n",
       "                    date  location  dob_x height_x  ...  win_percentage_x  \\\n",
       "0      November 02, 2019        92    835    5' 7\"  ...          0.800000   \n",
       "1     September 28, 2019        37    256    5' 8\"  ...          1.000000   \n",
       "2      November 16, 2019       126    612    5' 5\"  ...          0.588235   \n",
       "3       October 05, 2019        78    286    5' 5\"  ...          0.875000   \n",
       "4       October 18, 2019        23    466    6' 7\"  ...          0.666667   \n",
       "...                  ...       ...    ...      ...  ...               ...   \n",
       "3822  September 21, 2019        80    126    5' 6\"  ...          0.782609   \n",
       "3823  September 21, 2019        80    737    5' 2\"  ...          0.857143   \n",
       "3824  September 21, 2019        80    606    5' 9\"  ...          0.687500   \n",
       "3825  September 21, 2019        80    901    5' 8\"  ...          0.800000   \n",
       "3826  September 21, 2019        80    182    5' 7\"  ...          0.714286   \n",
       "\n",
       "      win_percentage_y  reach_advantage  total_fights_x  total_fights_y  \\\n",
       "0             0.846154             -3.0            20.0            13.0   \n",
       "1             0.714286              0.0            12.0            14.0   \n",
       "2             0.875000              0.0            17.0             8.0   \n",
       "3             0.687500              4.0            16.0            16.0   \n",
       "4             0.739130              7.0             9.0            23.0   \n",
       "...                ...              ...             ...             ...   \n",
       "3822          0.620690              1.0            23.0            29.0   \n",
       "3823          0.588235             -3.0            14.0            17.0   \n",
       "3824          0.588235              3.0            16.0            17.0   \n",
       "3825          0.666667              1.0            15.0            27.0   \n",
       "3826          0.909091              3.0            21.0            11.0   \n",
       "\n",
       "      finishing_rate_x  finishing_rate_y  age_x  age_y  age_difference  \n",
       "0             0.242500          0.406154     30     28               2  \n",
       "1             0.398333          0.094286     24     25              -1  \n",
       "2             0.211765          0.603750     31     25               6  \n",
       "3             0.196250          0.096250     27     29              -2  \n",
       "4             0.288889          0.269565     29     28               1  \n",
       "...                ...               ...    ...    ...             ...  \n",
       "3822          0.186087          0.092069     26     35              -9  \n",
       "3823          0.430714          0.351765     26     34              -8  \n",
       "3824          0.393750          0.211765     31     31               0  \n",
       "3825          0.510667          0.187037     26     29              -3  \n",
       "3826          0.156190          0.181818     25     26              -1  \n",
       "\n",
       "[3827 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleanedDataNEW_encoded.csv\") # original dataset\n",
    "##print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "'''keep = np.array([4,2,1,6,10,11,12,37,38,63,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,104,105,130,132,133,134,135,136,137,138,139,140,141,142,143,144,145]) - 1\n",
    "df = df.iloc[:,:] # interesting fields\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]) # date as datetime\n",
    "\n",
    "\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True) # replace empty string with nan\n",
    "df = df.fillna(np.nan) # Fill empty and NaNs values with NaN\n",
    "\n",
    "df = df.round(3) # format data\n",
    "\n",
    "df.rename(columns={ # some renaming\n",
    "    \"B_win_by_KO/TKO\": \"B_win_by_KO_TKO\",\n",
    "    \"R_win_by_KO/TKO\": \"R_win_by_KO_TKO\"},inplace=True)\n",
    "##print(f\"shape: {df.shape}\")\n",
    "\n",
    "# considering matches with a winner as this will be a binary classification\n",
    "drawRate = round(len(df[\"Winner\"][df[\"Winner\"]== \"Draw\"])/len(df.index)*100,3)\n",
    "print(f\"Draw rate is: {drawRate}%, converting to nan\")\n",
    "df[\"Winner\"] = df[\"Winner\"].replace(\"Draw\", np.nan) # convert to nan to be dropped later\n",
    "##df.dropna()'''\n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>decision_method</th>\n",
       "      <th>fight_duration_lastrnd</th>\n",
       "      <th>fight_duration_lastrnd_time</th>\n",
       "      <th>time_format</th>\n",
       "      <th>weight_class</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>dob_x</th>\n",
       "      <th>height_x</th>\n",
       "      <th>...</th>\n",
       "      <th>win_percentage_x</th>\n",
       "      <th>win_percentage_y</th>\n",
       "      <th>reach_advantage</th>\n",
       "      <th>total_fights_x</th>\n",
       "      <th>total_fights_y</th>\n",
       "      <th>finishing_rate_x</th>\n",
       "      <th>finishing_rate_y</th>\n",
       "      <th>age_x</th>\n",
       "      <th>age_y</th>\n",
       "      <th>age_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>February 03, 2018</td>\n",
       "      <td>15</td>\n",
       "      <td>342</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.162143</td>\n",
       "      <td>0.083913</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>June 03, 2017</td>\n",
       "      <td>112</td>\n",
       "      <td>578</td>\n",
       "      <td>6' 2\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.187333</td>\n",
       "      <td>0.261667</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>November 08, 2014</td>\n",
       "      <td>141</td>\n",
       "      <td>720</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.252222</td>\n",
       "      <td>0.053810</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>May 27, 2018</td>\n",
       "      <td>71</td>\n",
       "      <td>368</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.219375</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>June 26, 2011</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "      <td>5' 8\"</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.113571</td>\n",
       "      <td>0.166944</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      winner  decision_method  fight_duration_lastrnd  \\\n",
       "3253       1                5                       2   \n",
       "2732       1                7                       2   \n",
       "1814       1                4                       3   \n",
       "3389       1                7                       3   \n",
       "595        0                6                       2   \n",
       "\n",
       "      fight_duration_lastrnd_time  time_format  weight_class  \\\n",
       "3253                           56            1             7   \n",
       "2732                          222            1             7   \n",
       "1814                          292            1             2   \n",
       "3389                          154            1             2   \n",
       "595                           101            1             6   \n",
       "\n",
       "                   date  location  dob_x height_x  ...  win_percentage_x  \\\n",
       "3253  February 03, 2018        15    342    6' 2\"  ...          0.750000   \n",
       "2732      June 03, 2017       112    578    6' 2\"  ...          0.733333   \n",
       "1814  November 08, 2014       141    720    5' 8\"  ...          0.777778   \n",
       "3389       May 27, 2018        71    368    5' 8\"  ...          0.937500   \n",
       "595       June 26, 2011       106    112    5' 8\"  ...          0.714286   \n",
       "\n",
       "      win_percentage_y  reach_advantage  total_fights_x  total_fights_y  \\\n",
       "3253          0.695652              0.0            28.0            46.0   \n",
       "2732          0.666667              6.0            15.0            18.0   \n",
       "1814          0.571429              3.0             9.0            21.0   \n",
       "3389          0.750000              1.0            16.0            12.0   \n",
       "595           0.777778             -6.0            42.0            36.0   \n",
       "\n",
       "      finishing_rate_x  finishing_rate_y  age_x  age_y  age_difference  \n",
       "3253          0.162143          0.083913     34     29               5  \n",
       "2732          0.187333          0.261667     27     30              -3  \n",
       "1814          0.252222          0.053810     22     27              -5  \n",
       "3389          0.219375          0.140000     24     24               0  \n",
       "595           0.113571          0.166944     26     21               5  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##shuffling the data \n",
    "df_shuffled = df.sample(frac = 1)\n",
    "df_shuffled.head(n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal encoded dataset saved to data/ordinal_encoded_cleanedDataNEW.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/cleanedDataNEW.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the columns to encode\n",
    "columns_to_encode = ['decision_method', 'time_format', 'weight_class',]\n",
    "\n",
    "# Initialize the OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Apply ordinal encoding to the specified columns\n",
    "data[columns_to_encode] = ordinal_encoder.fit_transform(data[columns_to_encode])\n",
    "\n",
    "# Save the modified dataset\n",
    "output_file_path = 'data/ordinal_encoded_cleanedDataNEW.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Ordinal encoded dataset saved to {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split up the data \n",
    "df_shuffled.columns\n",
    "\n",
    "'''x = df_shuffled.drop([], axis = 1).values\n",
    "y = df_shuffled[\"Winner\"].values'''\n",
    "y = df_shuffled.iloc[:,0]\n",
    "x = df_shuffled.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomMinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.min_ = None\n",
    "        self.max_ = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        # Compute min and max values for each feature\n",
    "        self.min_ = np.min(data, axis=0)\n",
    "        self.max_ = np.max(data, axis=0)\n",
    "\n",
    "    def transform(self, data):\n",
    "        # Scale data to the range [0, 1]\n",
    "        return (data - self.min_) / (self.max_ - self.min_)\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y,test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''winners = y = df_shuffled[\"Winner\"].values'''\n",
    "\n",
    "scaler = CustomMinMaxScaler()\n",
    "\n",
    "xTrainScaled = scaler.fit_transform(xTrain)\n",
    "xTestScaled = scaler.fit_transform(xTest)\n",
    "yTrainScaled = scaler.fit_transform(yTrain)\n",
    "yTestScaled = scaler.fit_transform(yTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Assuming your data is preprocessed into X (features) and y (labels)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Convert Pandas Series to NumPy arrays if necessary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m xTrainScaled \u001b[38;5;241m=\u001b[39m xTrainScaled\u001b[38;5;241m.\u001b[39mto_numpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(xTrainScaled, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;28;01melse\u001b[39;00m xTrainScaled\n\u001b[0;32m---> 18\u001b[0m yTrainScaled \u001b[38;5;241m=\u001b[39m \u001b[43myTrainScaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(yTrain, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;28;01melse\u001b[39;00m yTrain\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Debugging: Check the shape of the input data\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxTrainScaled shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxTrainScaled\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, yTrain shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myTrain\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameters for GradientBoostingClassifier\n",
    "n_estimators = 100      # Number of boosting stages (trees)\n",
    "learning_rate = 0.2      # Step size at each iteration\n",
    "max_depth = 3            # Maximum depth of the individual trees\n",
    "subsample = 1.0          # Proportion of samples used to fit each tree\n",
    "min_samples_split = 2    # Minimum number of samples required to split an internal node\n",
    "min_samples_leaf = 1     # Minimum number of samples required to be at a leaf node\n",
    "max_features = None      # Number of features to consider for the best split\n",
    "\n",
    "# Assuming your data is preprocessed into X (features) and y (labels)\n",
    "\n",
    "# Convert Pandas Series to NumPy arrays if necessary\n",
    "xTrainScaled = xTrainScaled.to_numpy() if isinstance(xTrainScaled, pd.Series) else xTrainScaled\n",
    "yTrainScaled = yTrainScaled.to_numpy() if isinstance(yTrain, pd.Series) else yTrain\n",
    "\n",
    "# Debugging: Check the shape of the input data\n",
    "print(f\"xTrainScaled shape: {xTrainScaled.shape}, yTrain shape: {yTrain.shape}\")\n",
    "\n",
    "# Ensure that X is a 2D array (n_samples, n_features) and y is a 1D array (n_samples,)\n",
    "if len(xTrainScaled.shape) == 1:  # If X has only one feature (1D array)\n",
    "    xTrainScaled = xTrainScaled.reshape(-1, 1)  # Reshape it to be 2D (n_samples, 1)\n",
    "\n",
    "if len(yTrain.shape) > 1:  # If y has more than one column\n",
    "    yTrainScaled = yTrainScaled.reshape(-1, 1)  # Flatten it to be a 1D array\n",
    "\n",
    "# Double-check the shape again after reshaping\n",
    "print(f\"xTrainScaled shape after reshaping: {xTrainScaled.shape}, yTrain shape after reshaping: {yTrain.shape}\")\n",
    "\n",
    "# Define the Gradient Boosting model with the specified parameters\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    subsample=subsample,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    max_features=max_features,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(xTrainScaled, yTrainScaled)\n",
    "\n",
    "# Convert xTestScaled to numpy if it is a pandas Series, then reshape if it's 1D\n",
    "if isinstance(xTestScaled, pd.Series):\n",
    "    xTestScaled = xTestScaled.to_numpy()\n",
    "\n",
    "# Reshape xTestScaled if it's 1D\n",
    "if len(xTestScaled.shape) == 1:\n",
    "    xTestScaled = xTestScaled.reshape(-1, 1)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "y_pred = model.predict(xTestScaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(yTest, y_pred)\n",
    "\n",
    "# Calculate the precision of the model\n",
    "precision = precision_score(yTest, y_pred, average='binary')  # Use 'binary' for binary classification tasks\n",
    "\n",
    "# Print the final results\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Set Precision: {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrainScaled shape: (3061, 1), yTrain shape: (3061,)\n",
      "xTrainScaled shape after reshaping: (3061, 1), yTrain shape after reshaping: (3061,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshuat/UFC-Predictor/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [09:22:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.6123\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd  # Ensure pandas is imported if using pandas DataFrames or Series\n",
    "\n",
    "# Define the parameters for XGBClassifier\n",
    "n_estimators = 400      # Number of boosting stages (trees)\n",
    "learning_rate = 0.01    # Step size at each iteration\n",
    "max_depth = 3           # Maximum depth of the individual trees\n",
    "subsample = .8         # Proportion of samples used to fit each tree\n",
    "min_child_weight = 1    # Minimum sum of instance weights (hessian) needed in a child\n",
    "colsample_bytree = None # Proportion of features used for each tree (None defaults to 1.0)\n",
    "\n",
    "# Assuming your data is preprocessed into X (features) and y (labels)\n",
    "\n",
    "# Convert Pandas Series to NumPy arrays, if necessary\n",
    "xTrainScaled = xTrainScaled.to_numpy() if isinstance(xTrainScaled, pd.Series) else xTrainScaled\n",
    "yTrainScaled = yTrain.to_numpy() if isinstance(yTrain, pd.Series) else yTrain\n",
    "\n",
    "# Debugging: Check the shape of the input data\n",
    "print(f\"xTrainScaled shape: {xTrainScaled.shape}, yTrain shape: {yTrain.shape}\")\n",
    "\n",
    "# Ensure that X is a 2D array (n_samples, n_features) and y is a 1D array (n_samples,)\n",
    "if len(xTrainScaled.shape) == 1:  # If X has only one feature (1D array)\n",
    "    xTrainScaled = xTrainScaled.reshape(-1, 1)  # Reshape it to be 2D (n_samples, 1)\n",
    "\n",
    "if len(yTrainScaled.shape) > 1:  # If y has more than one column\n",
    "    yTrainScaled = yTrainScaled.reshape(-1)  # Flatten it to be a 1D array\n",
    "\n",
    "# Double-check the shape again after reshaping\n",
    "print(f\"xTrainScaled shape after reshaping: {xTrainScaled.shape}, yTrain shape after reshaping: {yTrainScaled.shape}\")\n",
    "\n",
    "# Define the XGBClassifier model with the specified parameters\n",
    "model = XGBClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    max_depth=max_depth,\n",
    "    subsample=subsample,\n",
    "    min_child_weight=min_child_weight,\n",
    "    colsample_bytree=colsample_bytree if colsample_bytree else 1.0,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False  # Add to suppress label encoder warning in XGBoost\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(xTrainScaled, yTrainScaled)\n",
    "\n",
    "# Convert xTestScaled to numpy if it is a pandas Series, then reshape if it's 1D\n",
    "if isinstance(xTestScaled, pd.Series):\n",
    "    xTestScaled = xTestScaled.to_numpy()\n",
    "\n",
    "# Reshape xTestScaled if it's 1D\n",
    "if len(xTestScaled.shape) == 1:\n",
    "    xTestScaled = xTestScaled.reshape(-1, 1)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "y_pred = model.predict(xTestScaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(yTest, y_pred)\n",
    "\n",
    "# Print the final results\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/cleanedDataNEW.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the columns to encode\n",
    "columns_to_encode = ['decision_method', 'time_format', 'weight_class']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "encoded_data = pd.get_dummies(data, columns=columns_to_encode, drop_first=True)\n",
    "\n",
    "# Save the modified dataset\n",
    "output_file_path = 'data/NEWencoded_cleanedDataNEW.csv'\n",
    "encoded_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_882688/2181337754.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "/tmp/ipykernel_882688/2181337754.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].median(), inplace=True)\n",
      "/tmp/ipykernel_882688/2181337754.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(X.median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used for training: ['fight_duration_lastrnd', 'height_x', 'n_draw_x', 'n_loss_x', 'n_win_x', 'reach_x', 'sig_str_abs_pM_x', 'sig_str_def_pct_x', 'sig_str_land_pM_x', 'sig_str_land_pct_x', 'sub_avg_x', 'td_avg_x', 'td_def_pct_x', 'td_land_pct_x', 'height_y', 'n_draw_y', 'n_loss_y', 'n_win_y', 'reach_y', 'sig_str_abs_pM_y', 'sig_str_def_pct_y', 'sig_str_land_pM_y', 'sig_str_land_pct_y', 'sub_avg_y', 'td_avg_y', 'td_def_pct_y', 'td_land_pct_y', 'win_percentage_x', 'win_percentage_y', 'reach_advantage', 'total_fights_x', 'total_fights_y', 'finishing_rate_x', 'finishing_rate_y', 'age_x', 'age_y', 'age_difference', 'decision_method_1', 'decision_method_2', 'decision_method_3', 'decision_method_4', 'decision_method_5', 'decision_method_6', 'decision_method_7', 'decision_method_8', 'stance_x_1', 'stance_x_2', 'stance_x_3', 'stance_y_1', 'stance_y_2', 'stance_y_3', 'time_format_1', 'time_format_2', 'time_format_3', 'weight_class_1', 'weight_class_2', 'weight_class_3', 'weight_class_4', 'weight_class_5', 'weight_class_6', 'weight_class_7', 'weight_class_8', 'weight_class_9', 'weight_class_10', 'weight_class_11', 'weight_class_12', 'weight_class_13', 'weight_class_14', 'weight_class_15', 'weight_class_16', 'weight_class_17', 'weight_class_18', 'weight_class_19', 'weight_class_20', 'weight_class_21', 'weight_class_22', 'weight_class_23', 'weight_class_24', 'weight_class_25', 'weight_class_26', 'weight_class_27', 'weight_class_28', 'weight_class_29', 'weight_class_30', 'weight_class_31', 'weight_class_32', 'weight_class_33', 'weight_class_34', 'weight_class_35', 'weight_class_36', 'weight_class_37', 'weight_class_38', 'weight_class_39', 'weight_class_40', 'weight_class_41', 'weight_class_42', 'weight_class_43', 'weight_class_44', 'weight_class_45', 'weight_class_46', 'weight_class_47', 'weight_class_48', 'weight_class_49', 'weight_class_50', 'weight_class_51', 'weight_class_52', 'weight_class_53', 'weight_class_54', 'weight_class_55', 'weight_class_56', 'weight_class_57', 'weight_class_58', 'weight_class_59', 'weight_class_60', 'weight_class_61']\n",
      "saved to data/transformedData.csv\n",
      "imputing missing vals\n",
      "Accuracy: 0.72\n",
      "Model saved to joblibs/gradient_boosting_model.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert height strings to numeric (in inches)\n",
    "def convert_height(height):\n",
    "    try:\n",
    "        parts = height.split(\"'\")\n",
    "        feet = int(parts[0])\n",
    "        inches = int(parts[1].replace('\"', '').strip())\n",
    "        return feet * 12 + inches\n",
    "    except:\n",
    "        return np.nan  # Return NaN if conversion fails\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data/cleanedDataNEW_encoded.csv\"  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert height columns to numeric\n",
    "if 'height_x' in data.columns:\n",
    "    data['height_x'] = data['height_x'].apply(convert_height)\n",
    "if 'height_y' in data.columns:\n",
    "    data['height_y'] = data['height_y'].apply(convert_height)\n",
    "\n",
    "# Fill missing height values with the median height\n",
    "for col in ['height_x', 'height_y']:\n",
    "    if col in data.columns:\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "\n",
    "# Define target column\n",
    "target = 'winner'\n",
    "\n",
    "# Handle categorical data\n",
    "categorical_columns = ['decision_method', 'stance_x', 'stance_y', 'time_format', 'weight_class']\n",
    "available_categorical = [col for col in categorical_columns if col in data.columns]\n",
    "data_encoded = pd.get_dummies(data, columns=available_categorical, drop_first=True)\n",
    "\n",
    "# Define the columns to exclude\n",
    "exclude_columns = [\n",
    "    'weight_x', 'weight_y', 'fight_duration_lastrnd_time', 'date', 'location',\n",
    "    'dob_x', 'name_x', 'dob_y', 'name_y', target  \n",
    "]\n",
    "\n",
    "# Prepare features for training by excluding specific columns\n",
    "existing_features = [col for col in data_encoded.columns if col not in exclude_columns]\n",
    "print(\"Features used for training:\", existing_features)\n",
    "\n",
    "transformed_file_path = \"data/transformedData.csv\"\n",
    "data_encoded.to_csv(transformed_file_path, index=False)\n",
    "print(f\"saved to {transformed_file_path}\")\n",
    "# Prepare data for training\n",
    "X = data_encoded[existing_features]\n",
    "y = data_encoded[target]\n",
    "\n",
    "# Check for missing values and handle them\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"imputing missing vals\")\n",
    "    X.fillna(X.median(), inplace=True)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,       # Number of trees\n",
    "    learning_rate=0.1,      # Learning rate\n",
    "    max_depth=3,            # Maximum tree depth\n",
    "    min_samples_split=2,    # Stop splitting nodes with maximum instances\n",
    "    subsample=1.0,          # Fraction of training instances\n",
    "    random_state=42         # Replicable training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "# print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib_file = \"joblibs/gradient_boosting_model.joblib\"  # Specify the file name\n",
    "joblib.dump(model, joblib_file)\n",
    "\n",
    "print(f\"Model saved to {joblib_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 2.1.3\n",
      "Joblib version: 1.4.2\n",
      "scikit-learn 1.5.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib \n",
    "import sklearn\n",
    "\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Joblib version:\", joblib.__version__)\n",
    "print(\"scikit-learn\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the Model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/TransformedData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/TransformedData.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Read the file into a DataFrame\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Specify the row index and the desired columns (replace with your selections)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m row_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Select the row you want (e.g., 0 for the first row)\u001b[39;00m\n",
      "File \u001b[0;32m~/UFC-Predictor/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UFC-Predictor/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/UFC-Predictor/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UFC-Predictor/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/UFC-Predictor/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/TransformedData.csv'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model\n",
    "testingModel = joblib.load(\"joblibs/gradient_boosting_model.joblib\")\n",
    "\n",
    "# Path to the input file (replace with your actual file path)\n",
    "file_path = \"data/transformedData.csv\"\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Specify the row index and the desired columns (replace with your selections)\n",
    "row_index = 3  # Select the row you want (e.g., 0 for the first row)\n",
    "desired_columns = np.array(['fight_duration_lastrnd', 'height_x', 'n_draw_x', 'n_loss_x', 'n_win_x', 'reach_x', 'sig_str_abs_pM_x', 'sig_str_def_pct_x', 'sig_str_land_pM_x', 'sig_str_land_pct_x', 'sub_avg_x', 'td_avg_x', 'td_def_pct_x', 'td_land_pct_x', 'height_y', 'n_draw_y', 'n_loss_y', 'n_win_y', 'reach_y', 'sig_str_abs_pM_y', 'sig_str_def_pct_y', 'sig_str_land_pM_y', 'sig_str_land_pct_y', 'sub_avg_y', 'td_avg_y', 'td_def_pct_y', 'td_land_pct_y', 'win_percentage_x', 'win_percentage_y', 'reach_advantage', 'total_fights_x', 'total_fights_y', 'finishing_rate_x', 'finishing_rate_y', 'age_x', 'age_y', 'age_difference', 'decision_method_1', 'decision_method_2', 'decision_method_3', 'decision_method_4', 'decision_method_5', 'decision_method_6', 'decision_method_7', 'decision_method_8', 'stance_x_1', 'stance_x_2', 'stance_x_3', 'stance_y_1', 'stance_y_2', 'stance_y_3', 'time_format_1', 'time_format_2', 'time_format_3', 'weight_class_1', 'weight_class_2', 'weight_class_3', 'weight_class_4', 'weight_class_5', 'weight_class_6', 'weight_class_7', 'weight_class_8', 'weight_class_9', 'weight_class_10', 'weight_class_11', 'weight_class_12', 'weight_class_13', 'weight_class_14', 'weight_class_15', 'weight_class_16', 'weight_class_17', 'weight_class_18', 'weight_class_19', 'weight_class_20', 'weight_class_21', 'weight_class_22', 'weight_class_23', 'weight_class_24', 'weight_class_25', 'weight_class_26', 'weight_class_27', 'weight_class_28', 'weight_class_29', 'weight_class_30', 'weight_class_31', 'weight_class_32', 'weight_class_33', 'weight_class_34', 'weight_class_35', 'weight_class_36', 'weight_class_37', 'weight_class_38', 'weight_class_39', 'weight_class_40', 'weight_class_41', 'weight_class_42', 'weight_class_43', 'weight_class_44', 'weight_class_45', 'weight_class_46', 'weight_class_47', 'weight_class_48', 'weight_class_49', 'weight_class_50', 'weight_class_51', 'weight_class_52', 'weight_class_53', 'weight_class_54', 'weight_class_55', 'weight_class_56', 'weight_class_57', 'weight_class_58', 'weight_class_59', 'weight_class_60', 'weight_class_61'])\n",
    "\n",
    "# Extract the selected row and columns\n",
    "selected_row = data.loc[row_index, desired_columns]\n",
    "\n",
    "# Convert the selected row into a NumPy array\n",
    "input_features = np.array(selected_row).astype(float)  # Ensure all values are numerical\n",
    "\n",
    "# Reshape the input for the model\n",
    "reshaped_input = input_features.reshape(1, -1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = testingModel.predict(reshaped_input)\n",
    "\n",
    "print(\"Prediction:\", predictions)\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
